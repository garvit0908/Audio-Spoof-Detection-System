{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import wave\n",
    "import hashlib\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
    "from cryptography.hazmat.primitives import serialization, hashes\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft, ifft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# === STEP 1: Load Audio Data (Scene Fake Dataset) ===\n",
    "def load_audio_features(dataset_path):\n",
    "    features, labels = [], []\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        folder = os.path.join(dataset_path, label)\n",
    "        for file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            y, sr = librosa.load(file_path, sr=16000)  # Load audio\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            features.append(np.mean(mfcc, axis=1))\n",
    "            labels.append(0 if label == \"real\" else 1)  # 0 = real, 1 = fake\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# === STEP 2: Watermarking using Spread Spectrum ===\n",
    "def spread_spectrum_watermark(audio_file, watermark_bits, output_file, alpha=0.01):\n",
    "    rate, audio = wavfile.read(audio_file)\n",
    "    audio = audio.astype(np.float32)\n",
    "    \n",
    "    # Generate pseudo-random sequence\n",
    "    pseudo_noise = np.random.randn(len(audio))\n",
    "    watermark_signal = pseudo_noise * alpha * watermark_bits.mean()\n",
    "\n",
    "    # Embed watermark\n",
    "    audio += watermark_signal\n",
    "    audio = np.int16(audio / np.max(np.abs(audio)) * 32767)\n",
    "    wavfile.write(output_file, rate, audio)\n",
    "    print(\"Watermark embedded.\")\n",
    "\n",
    "# === STEP 3: Digital Signature (RSA) ===\n",
    "# Generate RSA Keys\n",
    "def generate_rsa_keys():\n",
    "    private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
    "    public_key = private_key.public_key()\n",
    "    \n",
    "    # Save keys\n",
    "    with open(\"private_key.pem\", \"wb\") as f:\n",
    "        f.write(private_key.private_bytes(\n",
    "            encoding=serialization.Encoding.PEM,\n",
    "            format=serialization.PrivateFormat.TraditionalOpenSSL,\n",
    "            encryption_algorithm=serialization.NoEncryption()\n",
    "        ))\n",
    "    \n",
    "    with open(\"public_key.pem\", \"wb\") as f:\n",
    "        f.write(public_key.public_bytes(\n",
    "            encoding=serialization.Encoding.PEM,\n",
    "            format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
    "        ))\n",
    "    return private_key, public_key\n",
    "\n",
    "# Sign a File\n",
    "def sign_audio(file_path, private_key):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        hash_value = hashlib.sha256(file_data).digest()\n",
    "        signature = private_key.sign(\n",
    "            hash_value,\n",
    "            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "    with open(f\"{file_path}.sig\", \"wb\") as f:\n",
    "        f.write(signature)\n",
    "    print(\"Digital Signature Created.\")\n",
    "\n",
    "# Verify Signature\n",
    "def verify_audio(file_path, public_key):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        hash_value = hashlib.sha256(file_data).digest()\n",
    "\n",
    "    with open(f\"{file_path}.sig\", \"rb\") as f:\n",
    "        signature = f.read()\n",
    "\n",
    "    try:\n",
    "        public_key.verify(\n",
    "            signature,\n",
    "            hash_value,\n",
    "            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        print(\"Signature Verified: Authentic Audio.\")\n",
    "        return True\n",
    "    except:\n",
    "        print(\"Signature Verification Failed!\")\n",
    "        return False\n",
    "\n",
    "# === STEP 4: Machine Learning Classification (Detect Fake Audio) ===\n",
    "def train_model(features, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Model Accuracy: {model.score(X_test, y_test) * 100:.2f}%\")\n",
    "    joblib.dump(model, \"audio_classifier.pkl\")\n",
    "\n",
    "def classify_audio(file_path, model):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    feature = np.mean(mfcc, axis=1).reshape(1, -1)\n",
    "    prediction = model.predict(feature)\n",
    "    return \"Real\" if prediction == 0 else \"Fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import joblib\n",
    "import wave\n",
    "import hashlib\n",
    "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
    "from cryptography.hazmat.primitives import serialization, hashes\n",
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft, ifft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# === STEP 1: Load Audio Data (Scene Fake Dataset) ===\n",
    "def load_audio_features(dataset_path):\n",
    "    features, labels = [], []\n",
    "    for label in [\"real\", \"fake\"]:\n",
    "        folder = os.path.join(dataset_path, label)\n",
    "        for file in os.listdir(folder):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            y, sr = librosa.load(file_path, sr=16000)  # Load audio\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "            features.append(np.mean(mfcc, axis=1))\n",
    "            labels.append(0 if label == \"real\" else 1)  # 0 = real, 1 = fake\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# === STEP 2: Watermarking using Spread Spectrum ===\n",
    "def spread_spectrum_watermark(audio_file, watermark_bits, output_file, alpha=0.01):\n",
    "    rate, audio = wavfile.read(audio_file)\n",
    "    audio = audio.astype(np.float32)\n",
    "    \n",
    "    # Generate pseudo-random sequence\n",
    "    pseudo_noise = np.random.randn(len(audio))\n",
    "    watermark_signal = pseudo_noise * alpha * watermark_bits.mean()\n",
    "\n",
    "    # Embed watermark\n",
    "    audio += watermark_signal\n",
    "    audio = np.int16(audio / np.max(np.abs(audio)) * 32767)\n",
    "    wavfile.write(output_file, rate, audio)\n",
    "    print(f\"Watermark embedded in {output_file}\")\n",
    "\n",
    "# === STEP 3: Digital Signature (RSA) ===\n",
    "# Generate RSA Keys\n",
    "def generate_rsa_keys():\n",
    "    private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
    "    public_key = private_key.public_key()\n",
    "    \n",
    "    # Save keys\n",
    "    with open(\"private_key.pem\", \"wb\") as f:\n",
    "        f.write(private_key.private_bytes(\n",
    "            encoding=serialization.Encoding.PEM,\n",
    "            format=serialization.PrivateFormat.TraditionalOpenSSL,\n",
    "            encryption_algorithm=serialization.NoEncryption()\n",
    "        ))\n",
    "    \n",
    "    with open(\"public_key.pem\", \"wb\") as f:\n",
    "        f.write(public_key.public_bytes(\n",
    "            encoding=serialization.Encoding.PEM,\n",
    "            format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
    "        ))\n",
    "    return private_key, public_key\n",
    "\n",
    "# Sign a File\n",
    "def sign_audio(file_path, private_key):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        hash_value = hashlib.sha256(file_data).digest()\n",
    "        signature = private_key.sign(\n",
    "            hash_value,\n",
    "            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "    with open(f\"{file_path}.sig\", \"wb\") as f:\n",
    "        f.write(signature)\n",
    "    print(f\"Digital Signature Created for {file_path}\")\n",
    "\n",
    "# Verify Signature\n",
    "def verify_audio(file_path, public_key):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_data = f.read()\n",
    "        hash_value = hashlib.sha256(file_data).digest()\n",
    "\n",
    "    try:\n",
    "        with open(f\"{file_path}.sig\", \"rb\") as f:\n",
    "            signature = f.read()\n",
    "        public_key.verify(\n",
    "            signature,\n",
    "            hash_value,\n",
    "            padding.PSS(mgf=padding.MGF1(hashes.SHA256()), salt_length=padding.PSS.MAX_LENGTH),\n",
    "            hashes.SHA256()\n",
    "        )\n",
    "        print(\"Signature Verified: Authentic Audio.\")\n",
    "        return True\n",
    "    except:\n",
    "        print(\"Signature Verification Failed!\")\n",
    "        return False\n",
    "\n",
    "# === STEP 4: Machine Learning Classification (Detect Fake Audio) ===\n",
    "def train_model(features, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Model Accuracy: {model.score(X_test, y_test) * 100:.2f}%\")\n",
    "    joblib.dump(model, \"audio_classifier.pkl\")\n",
    "\n",
    "def classify_audio(file_path, model):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    feature = np.mean(mfcc, axis=1).reshape(1, -1)\n",
    "    prediction = model.predict(feature)\n",
    "    return \"Real\" if prediction == 0 else \"Fake\"\n",
    "\n",
    "# === MAIN FUNCTION TO EXECUTE WORKFLOW ===\n",
    "def main():\n",
    "    dataset_path = \"./archive/\"  # Folder containing \"real\" and \"fake\" subfolders\n",
    "    \n",
    "    # 1. Load Dataset & Train Model\n",
    "    print(\"Loading Dataset and Extracting Features...\")\n",
    "    features, labels = load_audio_features(dataset_path)\n",
    "    print(\"Training Model...\")\n",
    "    train_model(features, labels)\n",
    "    \n",
    "    # 2. Generate RSA Keys for Signing\n",
    "    print(\"Generating RSA Keys...\")\n",
    "    private_key, public_key = generate_rsa_keys()\n",
    "    \n",
    "    # 3. Apply Watermarking & Digital Signing\n",
    "    test_audio = \"./\"\n",
    "    watermarked_audio = \"test_audio_watermarked.wav\"\n",
    "    print(\"Embedding Watermark...\")\n",
    "    spread_spectrum_watermark(test_audio, np.random.randint(0, 2, size=100), watermarked_audio)\n",
    "    \n",
    "    print(\"Signing Audio File...\")\n",
    "    sign_audio(watermarked_audio, private_key)\n",
    "    \n",
    "    # 4. Testing Phase\n",
    "    print(\"Testing with New Audio File...\")\n",
    "    \n",
    "    # Step 1: Verify Watermark\n",
    "    print(\"Checking for Watermark...\")\n",
    "    # Assume watermark detection function exists; skipping implementation\n",
    "    watermark_detected = True  # Simulated detection\n",
    "    \n",
    "    if not watermark_detected:\n",
    "        print(\"Watermark Missing! Classified as SPOOFED.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Verify Digital Signature\n",
    "    print(\"Verifying Digital Signature...\")\n",
    "    if not verify_audio(watermarked_audio, public_key):\n",
    "        print(\"Invalid Digital Signature! Classified as SPOOFED.\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Extract Features & Classify\n",
    "    print(\"Extracting Features and Classifying Audio...\")\n",
    "    model = joblib.load(\"audio_classifier.pkl\")\n",
    "    result = classify_audio(watermarked_audio, model)\n",
    "    \n",
    "    print(f\"Final Decision: {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "No librosa.feature attribute gtcc",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 163\u001b[0m\n\u001b[0;32m    160\u001b[0m eval_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./archive/eval/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# path to the eval directory\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# test_dir = './archive' # path to the test directory\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m model, watermark_db, signature_db \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_scene_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Train on dev set.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# Example Test on the Eval set:\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label_dir \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[1;32mIn[2], line 93\u001b[0m, in \u001b[0;36mtrain_model_scene_fake\u001b[1;34m(train_dir, model_type)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model_scene_fake\u001b[39m(train_dir, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Trains the model with SceneFake data, watermarking and signature.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     features, labels, audio_paths \u001b[38;5;241m=\u001b[39m \u001b[43mload_scene_fake_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     watermark_db \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     95\u001b[0m     signature_db \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[2], line 85\u001b[0m, in \u001b[0;36mload_scene_fake_data\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     83\u001b[0m audio_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, label_dir, filename)\n\u001b[0;32m     84\u001b[0m audio, sr \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mload(audio_path, sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 85\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     86\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     87\u001b[0m audio_paths\u001b[38;5;241m.\u001b[39mappend(audio_path)\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(audio, sr)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extracts IGTCC and GTCC features.\"\"\"\u001b[39;00m\n\u001b[0;32m     52\u001b[0m igtcc \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mchroma_cens(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[1;32m---> 53\u001b[0m gtcc \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgtcc\u001b[49m(y\u001b[38;5;241m=\u001b[39maudio, sr\u001b[38;5;241m=\u001b[39msr)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate((igtcc\u001b[38;5;241m.\u001b[39mflatten(), gtcc\u001b[38;5;241m.\u001b[39mflatten()))\n",
      "File \u001b[1;32mc:\\Users\\mukhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lazy_loader\\__init__.py:94\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attr\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: No librosa.feature attribute gtcc"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.feature\n",
    "import hashlib\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import soundfile as sf\n",
    "import uuid\n",
    "\n",
    "# --- Audio Watermarking (AudioSeal) ---\n",
    "def embed_watermark(audio, watermark_strength=0.1):\n",
    "    \"\"\"Embeds a simple watermark into the audio.\"\"\"\n",
    "    watermark = np.random.rand(len(audio)) * watermark_strength\n",
    "    watermarked_audio = audio + watermark\n",
    "    return watermarked_audio, watermark\n",
    "\n",
    "def extract_watermark(watermarked_audio, original_audio=None):\n",
    "    \"\"\"Extracts the watermark. If original is not given, extracts noise as watermark\"\"\"\n",
    "    if original_audio is None:\n",
    "        return watermarked_audio #returning the audio itself as a fail safe for water mark fail.\n",
    "    return watermarked_audio - original_audio\n",
    "\n",
    "def verify_watermark(extracted_watermark, original_watermark, threshold=0.05):\n",
    "    \"\"\"Verifies the extracted watermark against the original.\"\"\"\n",
    "    if original_watermark is None:\n",
    "        return False #if original watermark is missing, fail.\n",
    "    difference = np.mean(np.abs(extracted_watermark - original_watermark))\n",
    "    return difference < threshold\n",
    "\n",
    "# --- Digital Signature (Cryptographic Hashing) ---\n",
    "def generate_signature(audio_path):\n",
    "    \"\"\"Generates a digital signature for an audio file.\"\"\"\n",
    "    with open(audio_path, 'rb') as f:\n",
    "        audio_bytes = f.read()\n",
    "        signature = hashlib.sha256(audio_bytes).hexdigest()\n",
    "    return signature\n",
    "\n",
    "def verify_signature(audio_path, original_signature):\n",
    "    \"\"\"Verifies the digital signature of an audio file.\"\"\"\n",
    "    return generate_signature(audio_path) == original_signature\n",
    "\n",
    "# --- Feature Extraction (IGTCC, GTCC) ---\n",
    "def extract_features(audio, sr):\n",
    "    \"\"\"Extracts IGTCC and GTCC features.\"\"\"\n",
    "    igtcc = librosa.feature.chroma_cens(y=audio, sr=sr)\n",
    "    gtcc = librosa.feature.gtcc(y=audio, sr=sr)\n",
    "    return np.concatenate((igtcc.flatten(), gtcc.flatten()))\n",
    "\n",
    "# --- Machine Learning Model (ResNet50 / MLP) ---\n",
    "def build_resnet50_model(input_shape, num_classes):\n",
    "    \"\"\"Builds a ResNet50 model.\"\"\"\n",
    "    base_model = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_mlp_model(input_shape, num_classes):\n",
    "    \"\"\"Builds an MLP model.\"\"\"\n",
    "    model = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', solver='adam', max_iter=500)\n",
    "    return model\n",
    "\n",
    "def load_scene_fake_data(directory):\n",
    "    \"\"\"Loads SceneFake data from a given directory.\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    audio_paths = []\n",
    "    for label_dir in ['real', 'fake']:\n",
    "        label = 0 if label_dir == 'real' else 1\n",
    "        for filename in os.listdir(os.path.join(directory, label_dir)):\n",
    "            if filename.endswith('.wav'):\n",
    "                audio_path = os.path.join(directory, label_dir, filename)\n",
    "                audio, sr = librosa.load(audio_path, sr=None)\n",
    "                features.append(extract_features(audio, sr))\n",
    "                labels.append(label)\n",
    "                audio_paths.append(audio_path)\n",
    "\n",
    "    return np.array(features), np.array(labels), audio_paths\n",
    "\n",
    "def train_model_scene_fake(train_dir, model_type='mlp'):\n",
    "    \"\"\"Trains the model with SceneFake data, watermarking and signature.\"\"\"\n",
    "    features, labels, audio_paths = load_scene_fake_data(train_dir)\n",
    "    watermark_db = {}\n",
    "    signature_db = {}\n",
    "    watermarked_paths = []\n",
    "\n",
    "    for i in range(len(audio_paths)):\n",
    "        if labels[i] == 0:  # Only watermark real audio\n",
    "            audio, sr = librosa.load(audio_paths[i], sr=None)\n",
    "            watermarked_audio, original_watermark = embed_watermark(audio)\n",
    "            signature = generate_signature(audio_paths[i])\n",
    "            temp_watermarked_path = f\"temp_watermarked_{uuid.uuid4()}.wav\"\n",
    "            sf.write(temp_watermarked_path, watermarked_audio, sr)\n",
    "            features[i] = extract_features(watermarked_audio, sr) #overwrites the real features with watermarked features.\n",
    "            watermark_db[os.path.basename(audio_paths[i])] = original_watermark\n",
    "            signature_db[os.path.basename(audio_paths[i])] = signature\n",
    "            watermarked_paths.append(temp_watermarked_path)\n",
    "    if model_type == 'resnet':\n",
    "        features = features.reshape(features.shape[0], 12, 12, 1) #Reshape for resnet.\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "        y_train_categorical = to_categorical(y_train)\n",
    "        y_test_categorical = to_categorical(y_test)\n",
    "        model = build_resnet50_model(input_shape=(12, 12, 1), num_classes=2)\n",
    "        model.fit(X_train, y_train_categorical, epochs=10, batch_size=32, validation_data=(X_test, y_test_categorical))\n",
    "        return model, watermark_db, signature_db\n",
    "\n",
    "    elif model_type == 'mlp':\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "        model = build_mlp_model(input_shape=features.shape[1], num_classes=2)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model, watermark_db, signature_db\n",
    "\n",
    "def test_model_scene_fake(audio_path, model, watermark_db, signature_db, model_type='mlp'):\n",
    "    \"\"\"Tests the model with SceneFake data, watermark and signature verification.\"\"\"\n",
    "    filename = os.path.basename(audio_path)\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # Watermark Verification\n",
    "    if filename in watermark_db:\n",
    "        original_audio, sr_original = librosa.load(os.path.join(train_dir, 'real', filename), sr=None)\n",
    "        extracted_watermark = extract_watermark(audio, original_audio)\n",
    "        if not verify_watermark(extracted_watermark, watermark_db[filename]):\n",
    "            return \"SPOOFED (Watermark Failed)\"\n",
    "    else:\n",
    "        extracted_watermark = extract_watermark(audio)\n",
    "        if np.mean(np.abs(extracted_watermark)) <0.0001:\n",
    "            return \"SPOOFED (Watermark Missing)\"\n",
    "\n",
    "    # Signature Verification\n",
    "    if filename in signature_db:\n",
    "        if not verify_signature(audio_path, signature_db[filename]):\n",
    "            return \"SPOOFED (Signature Failed)\"\n",
    "\n",
    "    # Feature Extraction and ML Classification\n",
    "    features = extract_features(audio, sr)\n",
    "    features = features.reshape(1, -1)\n",
    "\n",
    "    if model_type == 'resnet':\n",
    "        features = features.reshape(1, 12, 12, 1)\n",
    "        prediction = model.predict(features)\n",
    "        predicted_class = np.argmax(prediction)\n",
    "    elif model_type == 'mlp':\n",
    "        predicted_class = model.predict(features)[0]\n",
    "\n",
    "    return \"REAL\" if predicted_class == 0 else \"SPOOFED (ML)\"\n",
    "\n",
    "# --- Example Usage ---\n",
    "train_dir = './archive/dev/'  # Path to the 'dev' directory\n",
    "eval_dir = './archive/eval/' # path to the eval directory\n",
    "# test_dir = './archive' # path to the test directory\n",
    "\n",
    "model, watermark_db, signature_db = train_model_scene_fake(train_dir, model_type='mlp') # Train on dev set.\n",
    "\n",
    "# Example Test on the Eval set:\n",
    "for label_dir in ['real','fake']:\n",
    "    for filename in os.listdir(os.path.join(eval_dir,label_dir)):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(eval_dir, label_dir, filename)\n",
    "            result = test_model_scene_fake(audio_path, model, watermark_db, signature_db)\n",
    "            print(f\"{audio_path}: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
