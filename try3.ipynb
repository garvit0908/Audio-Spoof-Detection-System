{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Real Audio Files: 2548\n",
      "Total Fake Audio Files: 10295\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define dataset paths\n",
    "real_audio_path = \"./archive/dev/real\"\n",
    "fake_audio_path = \"./archive/dev/fake\"\n",
    "\n",
    "# Load real and fake audio files\n",
    "real_files = [os.path.join(real_audio_path, f) for f in os.listdir(real_audio_path) if f.endswith('.wav')]\n",
    "fake_files = [os.path.join(fake_audio_path, f) for f in os.listdir(fake_audio_path) if f.endswith('.wav')]\n",
    "\n",
    "print(f\"Total Real Audio Files: {len(real_files)}\")\n",
    "print(f\"Total Fake Audio Files: {len(fake_files)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now embed a watermark in real audio using audioseal\n",
    "import librosa\n",
    "import torch\n",
    "from audioseal import AudioSeal\n",
    "model = AudioSeal.load_generator(\"audioseal_wm_16bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab ispe algo lga ke dekhte hai mfcc features pe\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically ye tera binary classification problem hai ya to fake hoga ya real hoga\n",
    "def extract_features(file_path, n_mfcc=13):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=None)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # Take mean of each MFCC coefficient\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shape: (12843, 13) Labels Shape: (12843,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define paths for real and fake audio files\n",
    "real_audio_path = \"./archive/dev/real/\"\n",
    "fake_audio_path = \"./archive/dev/fake/\"\n",
    "\n",
    "# real_files = random.sample(os.listdir(real_audio_path), 50)\n",
    "# fake_files = random.sample(os.listdir(fake_audio_path), 50)\n",
    "\n",
    "\n",
    "real_files = os.listdir(real_audio_path)  \n",
    "fake_files = os.listdir(fake_audio_path)\n",
    "# Prepare dataset list\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Process real audios\n",
    "for file in real_files:\n",
    "    file_path = os.path.join(real_audio_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    if features is not None:\n",
    "        data.append(features)\n",
    "        labels.append(1)  # 1 for real audio\n",
    "\n",
    "# Process fake audios\n",
    "for file in fake_files:\n",
    "    file_path = os.path.join(fake_audio_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    if features is not None:\n",
    "        data.append(features)\n",
    "        labels.append(0)  # 0 for spoofed audio\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(data)\n",
    "y = np.array(labels)\n",
    "print(\"Feature Shape:\", X.shape, \"Labels Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9793694044375243\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2036\n",
      "           1       0.98      0.92      0.95       533\n",
      "\n",
      "    accuracy                           0.98      2569\n",
      "   macro avg       0.98      0.96      0.97      2569\n",
      "weighted avg       0.98      0.98      0.98      2569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classifier (Random Forest / SVM)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf = SVC(kernel='linear', C=1.0)  # Use SVM instead if needed\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8871156091864538\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2036\n",
      "           1       0.75      0.68      0.72       533\n",
      "\n",
      "    accuracy                           0.89      2569\n",
      "   macro avg       0.83      0.81      0.82      2569\n",
      "weighted avg       0.88      0.89      0.89      2569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now let us apply svm on it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model= SVC(kernel='linear', C=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from audioseal import AudioSeal\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = AudioSeal.load_generator(\"audioseal_wm_16bits\")\n",
    "\n",
    "def addWaterMark(audioPath, outputPath):\n",
    "    wav, sr = librosa.load(audioPath, sr=16000)\n",
    "\n",
    "    # Convert wav to a PyTorch tensor and add batch + channel dimensions\n",
    "    wav_tensor = torch.tensor(wav, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, T)\n",
    "\n",
    "    # Pass the tensor to the model\n",
    "    watermark = model.get_watermark(wav_tensor, sr)\n",
    "    \n",
    "\n",
    "    # Convert watermark to NumPy\n",
    "    watermark_np = watermark.squeeze().detach().cpu().numpy()  # Remove extra dimensions & move to CPU\n",
    "\n",
    "    # Ensure both arrays have the same shape\n",
    "    if watermark_np.shape != wav.shape:\n",
    "        watermark_np = np.resize(watermark_np, wav.shape)  # Resize watermark if needed\n",
    "\n",
    "    # Add the watermark to the original audio\n",
    "    watermarked_audio = wav + watermark_np\n",
    "\n",
    "    # Save the watermarked file\n",
    "    sf.write(outputPath, watermarked_audio, sr)\n",
    "\n",
    "# Example Usage\n",
    "addWaterMark(\"./archive/dev/real/B_0000_5_A.wav\", \"./watermark/watermarked.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-130.33653  ,  130.84656  ,   -1.77593  ,   36.66478  ,\n",
       "          2.545489 ,   20.664501 ,    0.7507467,   -0.776362 ,\n",
       "          3.1035469,    3.3764336,    6.7592845,    3.764939 ,\n",
       "          2.588349 ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now i have to extract features from both of them and look at the difference of water_marked and not watermarked audio\n",
    "original_features = extract_features(\"./archive/dev/real/B_0000_5_A.wav\")\n",
    "original_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-130.48146   ,  130.727     ,   -1.7407396 ,   36.790726  ,\n",
       "          2.5953507 ,   20.539675  ,    0.5089865 ,   -0.94782275,\n",
       "          3.1446311 ,    3.571531  ,    6.891216  ,    3.6549296 ,\n",
       "          2.3008022 ], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watermarked_features = extract_features(\"./watermark/watermarked.wav\")\n",
    "watermarked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files: 100%|██████████| 2548/2548 [29:25<00:00,  1.44it/s] \n"
     ]
    }
   ],
   "source": [
    "# hlka hlka change hua hai to ab agr hum lgye algo to kya frk aata hai lets see\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming real_files is a list of audio file paths\n",
    "cnt=0\n",
    "for audioPath in tqdm(real_files, desc=\"Processing Audio Files\"):\n",
    "    # print(audioPath)\n",
    "    output_path = f\"./watermark/watermarked_{cnt}.wav\"\n",
    "    addWaterMark(audioPath, output_path)\n",
    "    cnt=cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Shape: (12843, 13) Labels Shape: (12843,)\n"
     ]
    }
   ],
   "source": [
    "# ab waatermarked audio files pe model lgate hai featues extract krne ke baaad\n",
    "import random\n",
    "\n",
    "# Define paths for real and fake audio files\n",
    "real_audio_path = \"./watermark/\"\n",
    "fake_audio_path = \"./archive/dev/fake/\"\n",
    "\n",
    "# real_files = random.sample(os.listdir(real_audio_path), 50)\n",
    "# fake_files = random.sample(os.listdir(fake_audio_path), 50)\n",
    "\n",
    "\n",
    "real_files = os.listdir(real_audio_path)  \n",
    "fake_files = os.listdir(fake_audio_path)\n",
    "# Prepare dataset list\n",
    "data2 = []\n",
    "labels2 = []\n",
    "\n",
    "# Process real audios\n",
    "for file in real_files:\n",
    "    file_path = os.path.join(real_audio_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    if features is not None:\n",
    "        data2.append(features)\n",
    "        labels2.append(1)  # 1 for real audio\n",
    "\n",
    "# Process fake audios\n",
    "for file in fake_files:\n",
    "    file_path = os.path.join(fake_audio_path, file)\n",
    "    features = extract_features(file_path)\n",
    "    if features is not None:\n",
    "        data2.append(features)\n",
    "        labels2.append(0)  # 0 for spoofed audio\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(data)\n",
    "y = np.array(labels)\n",
    "print(\"Feature Shape:\", X.shape, \"Labels Shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9793694044375243\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2036\n",
      "           1       0.98      0.92      0.95       533\n",
      "\n",
      "    accuracy                           0.98      2569\n",
      "   macro avg       0.98      0.96      0.97      2569\n",
      "weighted avg       0.98      0.98      0.98      2569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a classifier (Random Forest / SVM)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf = SVC(kernel='linear', C=1.0)  # Use SVM instead if needed\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8871156091864538\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      2036\n",
      "           1       0.75      0.68      0.72       533\n",
      "\n",
      "    accuracy                           0.89      2569\n",
      "   macro avg       0.83      0.81      0.82      2569\n",
      "weighted avg       0.88      0.89      0.89      2569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets apply svm now\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model= SVC(kernel='linear', C=1.0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
